"""
Complete LLM-Powered Outage Analysis Agent
- Properly displays validation results (real vs false positive)
- Follows 2025 LangGraph best practices with MCP integration
- Clean logging with transparent error handling
- Fixed missing function and correct data filtering display
"""

import os
import json
import logging
import streamlit as st
import pandas as pd
import folium
from streamlit_folium import st_folium
from datetime import datetime, timedelta, date, time
import numpy as np
from typing import Dict, List, Optional, Tuple, TypedDict, Annotated
from dotenv import load_dotenv

# LangGraph imports - 2025 best practices
from langgraph.graph import StateGraph, END, START
from langgraph.checkpoint.memory import MemorySaver
from langgraph.prebuilt import ToolNode, create_react_agent
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool

# Pydantic imports with proper fallback
try:
    from pydantic import BaseModel, Field
except ImportError:
    try:
        from pydantic.v1 import BaseModel, Field
    except ImportError:
        class BaseModel:
            def __init__(self, **kwargs):
                for k, v in kwargs.items():
                    setattr(self, k, v)
        
        def Field(*args, **kwargs):
            return None

# LLM imports - Claude as default with OpenAI fallback
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

# Vector DB imports
import chromadb

# MCP imports for 2025 best practices
try:
    from langchain_mcp_adapters.client import MultiServerMCPClient
    MCP_AVAILABLE = True
    logger.info("MCP adapters available for enhanced tool integration")
except ImportError:
    MCP_AVAILABLE = False
    logger.warning("MCP adapters not available - install with: pip install langchain-mcp-adapters")

# Load environment variables
load_dotenv()

# Set up clean logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== ENHANCED STATE MANAGEMENT ====================
class OutageAnalysisState(TypedDict):
    """2025 LangGraph State Management"""
    dataset_loaded: bool
    validation_complete: bool
    raw_dataset_summary: Dict
    validation_results: Dict
    filtered_summary: Dict  # Summary after false positive filtering
    current_window_analysis: Optional[Dict]
    chat_context: Dict
    errors: List[str]

# ==================== LLM MANAGER WITH 2025 BEST PRACTICES ====================
class LLMManager:
    """Enhanced LLM manager following 2025 patterns"""
    
    def __init__(self):
        self.llm = self._initialize_llm()
        
    def _initialize_llm(self):
        """Initialize LLM with Claude as primary choice"""
        try:
            if os.getenv("ANTHROPIC_API_KEY"):
                logger.info("ğŸ¤– Using Anthropic Claude (recommended)")
                return ChatAnthropic(
                    model="claude-3-sonnet-20240229",
                    temperature=0.1,
                    streaming=True
                )
            elif os.getenv("OPENAI_API_KEY"):
                logger.info("ğŸ¤– Using OpenAI GPT-4 (fallback)")
                return ChatOpenAI(
                    model="gpt-4-turbo-preview", 
                    temperature=0.1,
                    streaming=True
                )
            else:
                logger.error("âŒ No LLM API keys found")
                raise ValueError("Please set ANTHROPIC_API_KEY (recommended) or OPENAI_API_KEY in your .env file")
        except Exception as e:
            logger.error(f"âŒ LLM initialization failed: {str(e)}")
            raise
    
    def get_llm(self):
        return self.llm

# ==================== WEATHER SERVICE ====================
class WeatherService:
    """Weather service for validation using Open-Meteo API"""
    
    def __init__(self):
        self.base_url = "https://archive-api.open-meteo.com/v1/archive"
        
    def get_historical_weather(self, lat: float, lon: float, date: datetime) -> Dict:
        """Fetch weather data for validation"""
        try:
            date_str = date.strftime("%Y-%m-%d")
            
            params = {
                "latitude": lat,
                "longitude": lon,
                "start_date": date_str,
                "end_date": date_str,
                "hourly": "temperature_2m,precipitation,windspeed_10m,windgusts_10m,snowfall",
                "timezone": "America/Chicago"
            }
            
            import requests
            response = requests.get(self.base_url, params=params, timeout=10)
            response.raise_for_status()
            
            data = response.json()
            hourly_data = data.get('hourly', {})
            
            # Get data for the specific hour
            target_hour = min(date.hour, len(hourly_data.get('temperature_2m', [])) - 1) if hourly_data.get('temperature_2m') else 0
            
            return {
                'timestamp': date.isoformat(),
                'coordinates': {'lat': lat, 'lon': lon},
                'temperature': self._safe_get(hourly_data.get('temperature_2m', []), target_hour),
                'precipitation': self._safe_get(hourly_data.get('precipitation', []), target_hour),
                'wind_speed': self._safe_get(hourly_data.get('windspeed_10m', []), target_hour),
                'wind_gusts': self._safe_get(hourly_data.get('windgusts_10m', []), target_hour),
                'snowfall': self._safe_get(hourly_data.get('snowfall', []), target_hour),
                'api_status': 'success'
            }
            
        except requests.exceptions.RequestException as e:
            logger.error(f"âš ï¸  Weather API request failed: {str(e)}")
            return {'error': f'Weather API error: {str(e)}', 'timestamp': date.isoformat(), 'api_status': 'failed'}
        except Exception as e:
            logger.error(f"âš ï¸  Weather service error: {str(e)}")
            return {'error': f'Weather service error: {str(e)}', 'timestamp': date.isoformat(), 'api_status': 'failed'}
    
    def _safe_get(self, data_list: List, index: int):
        """Safely get data from list"""
        if not data_list or index >= len(data_list) or index < 0:
            return None
        return data_list[index]

# ==================== VECTOR DATABASE ====================
class OutageVectorDB:
    """Vector database for outage data management"""
    
    def __init__(self):
        try:
            self.client = chromadb.PersistentClient(path="./chroma_db")
            
            try:
                self.collection = self.client.get_collection("outages")
                logger.info("âœ… Connected to existing outages collection")
            except:
                self.collection = self.client.create_collection("outages")
                logger.info("âœ… Created new outages collection")
        except Exception as e:
            logger.error(f"âŒ Vector DB initialization failed: {str(e)}")
            raise
    
    def load_outage_data(self, df: pd.DataFrame) -> Dict:
        """Load data and return summary"""
        try:
            logger.info(f"ğŸ“Š Loading {len(df)} outage records into vector database")
            
            # Clear existing data
            try:
                self.client.delete_collection("outages")
                self.collection = self.client.create_collection("outages")
            except:
                pass
            
            documents = []
            metadatas = []
            ids = []
            
            for idx, row in df.iterrows():
                doc_text = f"""Power outage on {row['DATETIME']} at coordinates {row['LATITUDE']}, {row['LONGITUDE']} affecting {row['CUSTOMERS']} customers."""
                
                metadata = {
                    'datetime': row['DATETIME'],
                    'latitude': float(row['LATITUDE']),
                    'longitude': float(row['LONGITUDE']),
                    'customers': int(row['CUSTOMERS']),
                    'date': row['DATETIME'][:10],
                    'hour': int(row['DATETIME'][11:13]) if len(row['DATETIME']) > 11 else 0
                }
                
                documents.append(doc_text.strip())
                metadatas.append(metadata)
                ids.append(f"outage_{idx}")
            
            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            # Generate raw dataset summary
            summary = self._generate_raw_summary(df)
            logger.info("âœ… Data loaded successfully")
            return summary
            
        except Exception as e:
            logger.error(f"âŒ Error loading data: {str(e)}")
            raise
    
    def _generate_raw_summary(self, df: pd.DataFrame) -> Dict:
        """Generate summary of raw dataset before validation"""
        try:
            df['datetime_parsed'] = pd.to_datetime(df['DATETIME'])
            
            return {
                "total_reports": int(len(df)),
                "date_range": {
                    "start": df['datetime_parsed'].min().strftime('%Y-%m-%d'),
                    "end": df['datetime_parsed'].max().strftime('%Y-%m-%d')
                },
                "raw_customer_claims": {
                    "total_claimed": int(df['CUSTOMERS'].sum()),
                    "avg_per_report": float(df['CUSTOMERS'].mean()),
                    "max_single_report": int(df['CUSTOMERS'].max())
                },
                "geographic_coverage": {
                    "lat_range": f"{float(df['LATITUDE'].min()):.3f} to {float(df['LATITUDE'].max()):.3f}",
                    "lon_range": f"{float(df['LONGITUDE'].min()):.3f} to {float(df['LONGITUDE'].max()):.3f}",
                    "center": [float(df['LATITUDE'].mean()), float(df['LONGITUDE'].mean())]
                }
            }
        except Exception as e:
            logger.error(f"âŒ Error generating summary: {str(e)}")
            return {"error": str(e)}

# ==================== LLM TOOLS FOLLOWING 2025 PATTERNS ====================

@tool
def validate_outage_report(outage_report: dict, weather_data: dict) -> str:
    """Validate outage report against weather conditions using LLM analysis"""
    try:
        llm_manager = LLMManager()
        
        validation_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert power grid engineer specializing in outage validation.

Your task: Determine if an outage REPORT is REAL or FALSE POSITIVE based on weather conditions.

FALSE POSITIVES occur when:
- Weather conditions are mild (winds <25 mph, minimal precipitation, normal temperatures)
- Equipment sensor malfunctions
- Data processing errors
- Communication glitches

REAL OUTAGES are caused by:
- High winds: >25 mph sustained or >35 mph gusts
- Heavy precipitation: >0.5 inches/hour
- Ice/snow accumulation: >2 inches
- Temperature extremes: <10Â°F or >95Â°F
- Lightning/storms
- Equipment failures during severe weather

Respond with 'REAL OUTAGE' or 'FALSE POSITIVE' followed by detailed technical reasoning."""),
            ("human", """Analyze this outage report:

REPORT DETAILS:
Time: {datetime}
Location: {latitude}, {longitude}
Customers Claimed: {customers}

WEATHER CONDITIONS:
{weather_summary}

Classification: REAL OUTAGE or FALSE POSITIVE? Provide detailed analysis.""")
        ])
        
        # Format weather data
        if weather_data.get('api_status') == 'failed':
            weather_summary = f"Weather data unavailable: {weather_data.get('error', 'Unknown error')}"
        else:
            weather_summary = f"""
Temperature: {weather_data.get('temperature', 'N/A')}Â°C
Precipitation: {weather_data.get('precipitation', 'N/A')} mm/h
Wind Speed: {weather_data.get('wind_speed', 'N/A')} km/h
Wind Gusts: {weather_data.get('wind_gusts', 'N/A')} km/h
Snowfall: {weather_data.get('snowfall', 'N/A')} cm
"""
        
        chain = validation_prompt | llm_manager.get_llm()
        response = chain.invoke({
            "datetime": outage_report.get('datetime', 'Unknown'),
            "latitude": outage_report.get('latitude', 'Unknown'),
            "longitude": outage_report.get('longitude', 'Unknown'),
            "customers": outage_report.get('customers', 'Unknown'),
            "weather_summary": weather_summary
        })
        
        return response.content
        
    except Exception as e:
        logger.error(f"âŒ Validation error: {str(e)}")
        return f"VALIDATION ERROR: {str(e)}"

@tool
def chat_about_results(question: str, context: dict) -> str:
    """Chat about validation results with full context"""
    try:
        llm_manager = LLMManager()
        
        chat_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert power grid operations assistant. You have completed validation of outage reports, determining which are real outages vs false positives based on weather analysis.

You can help users understand:
1. Why specific reports were classified as false positives
2. What weather conditions caused real outages  
3. Patterns in false positive causes
4. Operational recommendations
5. Infrastructure improvements

Be specific and provide actionable insights based on the validation results."""),
            ("human", "{user_question}\n\nValidation Context:\n{analysis_context}")
        ])
        
        chain = chat_prompt | llm_manager.get_llm()
        
        response = chain.invoke({
            "user_question": question,
            "analysis_context": json.dumps(context, indent=2, default=str)
        })
        
        return response.content
        
    except Exception as e:
        logger.error(f"âŒ Chat error: {str(e)}")
        return f"Chat error: {str(e)}"

# ==================== MAIN VALIDATION LOGIC ====================
def validate_all_reports(df: pd.DataFrame) -> Dict:
    """Validate all outage reports and return comprehensive results"""
    
    weather_service = WeatherService()
    real_outages = []
    false_positives = []
    validation_errors = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    logger.info(f"ğŸ” Starting validation of {len(df)} outage reports")
    
    for idx, row in df.iterrows():
        progress = (idx + 1) / len(df)
        progress_bar.progress(progress)
        status_text.text(f"Validating report {idx+1}/{len(df)}: {row['CUSTOMERS']} customers claimed")
        
        try:
            # Parse datetime
            report_datetime = datetime.strptime(row['DATETIME'], "%Y-%m-%d %H:%M:%S")
            
            # Get weather data
            weather = weather_service.get_historical_weather(
                lat=row['LATITUDE'],
                lon=row['LONGITUDE'],
                date=report_datetime
            )
            
            # Prepare report data
            report_data = {
                'datetime': row['DATETIME'],
                'latitude': row['LATITUDE'],
                'longitude': row['LONGITUDE'],
                'customers': row['CUSTOMERS']
            }
            
            # Validate with LLM
            validation_result = validate_outage_report.invoke({
                "outage_report": report_data,
                "weather_data": weather
            })
            
            # Determine classification
            is_real = "REAL OUTAGE" in validation_result.upper()
            
            result_entry = {
                **report_data,
                'weather_data': weather,
                'claude_analysis': validation_result,
                'is_real_outage': is_real
            }
            
            if is_real:
                real_outages.append(result_entry)
            else:
                false_positives.append(result_entry)
                
        except Exception as e:
            logger.error(f"âŒ Error validating report {idx}: {str(e)}")
            validation_errors.append(f"Report {idx}: {str(e)}")
    
    progress_bar.empty()
    status_text.empty()
    
    # Calculate comprehensive statistics
    total_reports = len(df)
    real_count = len(real_outages)
    false_count = len(false_positives)
    
    # Calculate actual customer impact (only real outages)
    actual_customers_affected = sum(r['customers'] for r in real_outages)
    claimed_customers_total = int(df['CUSTOMERS'].sum())
    
    logger.info(f"âœ… Validation complete: {real_count} real, {false_count} false positives")
    
    return {
        'total_reports': total_reports,
        'real_outages': real_outages,
        'false_positives': false_positives,
        'validation_errors': validation_errors,
        'statistics': {
            'real_count': real_count,
            'false_positive_count': false_count,
            'false_positive_rate': (false_count / total_reports * 100) if total_reports > 0 else 0,
            'total_customers_actually_affected': actual_customers_affected,
            'total_customers_claimed': claimed_customers_total,
            'customer_impact_reduction': claimed_customers_total - actual_customers_affected
        }
    }

# ==================== UI FUNCTIONS ====================
def display_validation_results():
    """Display validation results with proper filtering - THE MISSING FUNCTION!"""
    
    st.header("ğŸ” Validation Results - Real vs False Positive")
    
    validation_results = st.session_state.analysis_state.get('validation_results', {})
    
    if not validation_results:
        st.warning("âš ï¸ No validation results available")
        return
    
    stats = validation_results.get('statistics', {})
    
    # Key metrics comparing raw vs validated data
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Total Reports", 
            f"{stats.get('real_count', 0) + stats.get('false_positive_count', 0):,}",
            help="Original number of outage reports"
        )
    
    with col2:
        st.metric(
            "Real Outages", 
            f"{stats.get('real_count', 0):,}",
            delta=f"-{stats.get('false_positive_count', 0)} false positives",
            delta_color="normal",
            help="Confirmed outages after validation"
        )
    
    with col3:
        # THIS IS THE CORRECTED LINE - showing actual customers affected, not claimed
        st.metric(
            "Actual Customers Affected", 
            f"{stats.get('total_customers_actually_affected', 0):,}",
            delta=f"-{stats.get('customer_impact_reduction', 0):,} filtered out",
            delta_color="normal",
            help="Customers affected by real outages only"
        )
    
    with col4:
        st.metric(
            "False Positive Rate", 
            f"{stats.get('false_positive_rate', 0):.1f}%",
            help="Percentage of reports that were false positives"
        )
    
    # Detailed breakdown
    st.subheader("ğŸ“Š Validation Breakdown")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.info(f"""
        **Real Outages Found:**
        - Count: {stats.get('real_count', 0):,}
        - Customers Affected: {stats.get('total_customers_actually_affected', 0):,}
        """)
    
    with col2:
        st.warning(f"""
        **False Positives Filtered:**
        - Count: {stats.get('false_positive_count', 0):,}
        - Customer Claims Removed: {stats.get('customer_impact_reduction', 0):,}
        """)
    
    # Show sample results
    if st.checkbox("ğŸ” Show Sample Validation Results"):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("âœ… Sample Real Outages")
            real_outages = validation_results.get('real_outages', [])
            if real_outages:
                sample_real = pd.DataFrame(real_outages[:5])
                st.dataframe(sample_real[['datetime', 'customers', 'latitude', 'longitude']])
            else:
                st.write("No real outages found")
        
        with col2:
            st.subheader("âŒ Sample False Positives")
            false_positives = validation_results.get('false_positives', [])
            if false_positives:
                sample_false = pd.DataFrame(false_positives[:5])
                st.dataframe(sample_false[['datetime', 'customers', 'latitude', 'longitude']])
            else:
                st.write("No false positives found")

def display_map_visualization():
    """Display map with real outages vs false positives"""
    
    validation_results = st.session_state.analysis_state.get('validation_results', {})
    
    if not validation_results:
        return
        
    st.subheader("ğŸ—ºï¸ Outage Map - Real vs False Positive")
    
    real_outages = validation_results.get('real_outages', [])
    false_positives = validation_results.get('false_positives', [])
    
    if not real_outages and not false_positives:
        st.warning("No outage data to display on map")
        return
    
    # Calculate map center
    all_outages = real_outages + false_positives
    if all_outages:
        center_lat = sum(o['latitude'] for o in all_outages) / len(all_outages)
        center_lon = sum(o['longitude'] for o in all_outages) / len(all_outages)
        
        m = folium.Map(location=[center_lat, center_lon], zoom_start=8)
        
        # Add real outages in red
        for outage in real_outages:
            folium.CircleMarker(
                location=[outage['latitude'], outage['longitude']],
                radius=max(5, min(15, outage['customers'] * 0.01)),
                popup=f"REAL OUTAGE<br>Time: {outage['datetime']}<br>Customers: {outage['customers']}",
                tooltip=f"Real Outage: {outage['customers']} customers",
                color='red',
                fillColor='red',
                fillOpacity=0.7
            ).add_to(m)
        
        # Add false positives in gray
        for outage in false_positives:
            folium.CircleMarker(
                location=[outage['latitude'], outage['longitude']],
                radius=max(3, min(10, outage['customers'] * 0.005)),
                popup=f"FALSE POSITIVE<br>Time: {outage['datetime']}<br>Customers Claimed: {outage['customers']}",
                tooltip=f"False Positive: {outage['customers']} customers claimed",
                color='gray',
                fillColor='gray',
                fillOpacity=0.3
            ).add_to(m)
        
        # Add legend
        legend_html = '''
        <div style="position: fixed; 
                    bottom: 50px; left: 50px; width: 150px; height: 90px; 
                    background-color: white; border:2px solid grey; z-index:9999; 
                    font-size:14px; padding: 10px">
        <p><b>Legend</b></p>
        <p><i class="fa fa-circle" style="color:red"></i> Real Outages</p>
        <p><i class="fa fa-circle" style="color:gray"></i> False Positives</p>
        </div>
        '''
        m.get_root().html.add_child(folium.Element(legend_html))
        
        st_folium(m, width=700, height=500)

def display_chat_interface():
    """Display chat interface for validation results"""
    
    st.header("ğŸ’¬ Chat with Claude about Validation Results")
    
    # Display chat history
    for chat in st.session_state.chat_history:
        if chat['role'] == 'user':
            st.markdown(f"**ğŸ™‹ You:** {chat['content']}")
        else:
            st.markdown(f"**ğŸ¤– Claude:** {chat['content']}")
    
    # Chat input
    user_question = st.text_input(
        "Ask about your validation results:",
        placeholder="e.g., 'Why were so many reports false positives?' or 'What weather caused the real outages?'",
        key="chat_input"
    )
    
    # Quick question buttons
    st.write("**Quick Questions:**")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("âŒ Why false positives?"):
            user_question = "Why were these reports classified as false positives? What were the main reasons?"
    
    with col2:
        if st.button("âš¡ Real outage causes?"):
            user_question = "What weather conditions caused the confirmed real outages?"
    
    with col3:
        if st.button("ğŸ“Š Summary?"):
            user_question = "Provide a summary of the validation results and recommendations."
    
    if st.button("ğŸ’­ Ask Claude") and user_question:
        with st.spinner("ğŸ¤– Claude analyzing..."):
            try:
                # Prepare context with validation results
                context = st.session_state.analysis_state.get('chat_context', {})
                
                response = chat_about_results.invoke({
                    "question": user_question,
                    "context": context
                })
                
                # Add to history
                st.session_state.chat_history.extend([
                    {'role': 'user', 'content': user_question},
                    {'role': 'assistant', 'content': response}
                ])
                
                st.rerun()
                
            except Exception as e:
                st.error(f"âŒ Chat error: {str(e)}")
    
    # Clear chat
    if st.button("ğŸ—‘ï¸ Clear Chat"):
        st.session_state.chat_history = []
        st.rerun()

# ==================== MAIN APPLICATION ====================
def main():
    """Main Streamlit application"""
    
    st.set_page_config(
        page_title="Outage Analysis Agent - 2025",
        page_icon="ğŸ¤–âš¡",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Initialize session state
    if 'analysis_state' not in st.session_state:
        st.session_state.analysis_state = {
            'dataset_loaded': False,
            'validation_complete': False,
            'raw_dataset_summary': {},
            'validation_results': {},
            'filtered_summary': {},
            'current_window_analysis': None,
            'chat_context': {},
            'errors': []
        }
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    
    st.title("ğŸ¤–âš¡ Advanced Outage Analysis Agent")
    st.markdown("**Claude-powered outage validation with false positive detection using 2025 LangGraph patterns**")
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ”§ Configuration")
        
        # LLM Status Check
        try:
            llm_manager = LLMManager()
            st.success("âœ… Claude Connected")
        except ValueError as e:
            st.error(f"âŒ {str(e)}")
            st.info("ğŸ’¡ Add your API key to .env file")
            return
        except Exception as e:
            st.error(f"âŒ LLM Error: {str(e)}")
            return
        
        if MCP_AVAILABLE:
            st.success("âœ… MCP Integration Available")
        else:
            st.warning("âš ï¸ MCP Not Available")
        
        st.divider()
        
        # Data Upload Section
        st.header("ğŸ“ Data Upload")
        uploaded_file = st.file_uploader(
            "Upload Outage CSV", 
            type=['csv'],
            help="CSV should have columns: DATETIME, LATITUDE, LONGITUDE, CUSTOMERS"
        )
        
        if uploaded_file is not None and not st.session_state.analysis_state['dataset_loaded']:
            try:
                df = pd.read_csv(uploaded_file)
                
                # Validate required columns
                required_columns = ['DATETIME', 'LATITUDE', 'LONGITUDE', 'CUSTOMERS']
                if not all(col in df.columns for col in required_columns):
                    st.error(f"âŒ Missing required columns: {required_columns}")
                    return
                
                st.success(f"ğŸ“Š Loaded {len(df)} records")
                st.write(f"**Columns:** {list(df.columns)}")
                
                if st.button("ğŸ” Start Validation Process"):
                    with st.spinner("ğŸ¤– Processing with Claude..."):
                        try:
                            # Load into vector DB
                            vector_db = OutageVectorDB()
                            raw_summary = vector_db.load_outage_data(df)
                            
                            # Validate all reports
                            validation_results = validate_all_reports(df)
                            
                            # Update session state
                            st.session_state.analysis_state.update({
                                'dataset_loaded': True,
                                'validation_complete': True,
                                'raw_dataset_summary': raw_summary,
                                'validation_results': validation_results,
                                'chat_context': {
                                    'raw_summary': raw_summary,
                                    'validation_results': validation_results
                                }
                            })
                            
                            st.success("âœ… Validation complete!")
                            st.rerun()
                            
                        except Exception as e:
                            st.error(f"âŒ Validation failed: {str(e)}")
                            logger.error(f"Validation error: {str(e)}")
                        
            except Exception as e:
                st.error(f"âŒ Error loading CSV: {str(e)}")
        
        # Show status
        if st.session_state.analysis_state['validation_complete']:
            st.success("âœ… Validation Complete")
            validation_stats = st.session_state.analysis_state['validation_results'].get('statistics', {})
            st.write(f"**Real Outages:** {validation_stats.get('real_count', 0)}")
            st.write(f"**False Positives:** {validation_stats.get('false_positive_count', 0)}")
            st.write(f"**Accuracy:** {100 - validation_stats.get('false_positive_rate', 0):.1f}%")
    
    # Main content area
    if not st.session_state.analysis_state['validation_complete']:
        st.info("ğŸ‘† Please upload your CSV file and start the validation process")
        
        # Show example data format
        with st.expander("ğŸ“‹ Expected CSV Format"):
            st.code("""
DATETIME,LATITUDE,LONGITUDE,CUSTOMERS
2022-01-01 00:15:00,40.7128,-74.0060,150
2022-01-01 01:30:00,40.7589,-73.9851,200
2022-01-01 02:45:00,40.6892,-74.0445,75
            """)
        return
    
    # Display validation results
    display_validation_results()
    
    st.divider()
    
    # Map visualization
    display_map_visualization()
    
    st.divider()
    
    # Time window analysis section
    st.header("ğŸ¯ Time Window Analysis")
    
    raw_summary = st.session_state.analysis_state.get('raw_dataset_summary', {})
    date_range = raw_summary.get('date_range', {})
    
    if date_range.get('start') and date_range.get('end'):
        min_date = datetime.strptime(date_range['start'], '%Y-%m-%d').date()
        max_date = datetime.strptime(date_range['end'], '%Y-%m-%d').date()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“… Start Date & Time")
            start_date = st.date_input("Start Date:", min_value=min_date, max_value=max_date, value=min_date)
            start_time = st.time_input("Start Time:", value=time(0, 0))
        
        with col2:
            st.subheader("ğŸ“… End Date & Time")
            end_date = st.date_input("End Date:", min_value=min_date, max_value=max_date, value=min_date)
            end_time = st.time_input("End Time:", value=time(23, 59))
        
        start_datetime = datetime.combine(start_date, start_time)
        end_datetime = datetime.combine(end_date, end_time)
        
        if st.button("ğŸ” Analyze Time Window"):
            analyze_time_window(start_datetime, end_datetime)
    
    st.divider()
    
    # Chat interface
    display_chat_interface()

def analyze_time_window(start_datetime: datetime, end_datetime: datetime):
    """Analyze specific time window with validation results"""
    
    with st.spinner(f"ğŸ¤– Analyzing {start_datetime} to {end_datetime}..."):
        try:
            validation_results = st.session_state.analysis_state.get('validation_results', {})
            
            if not validation_results:
                st.error("âŒ No validation results available")
                return
            
            # Filter real outages and false positives by time window
            real_outages = validation_results.get('real_outages', [])
            false_positives = validation_results.get('false_positives', [])
            
            def in_time_window(outage_datetime_str):
                try:
                    outage_dt = datetime.strptime(outage_datetime_str, '%Y-%m-%d %H:%M:%S')
                    return start_datetime <= outage_dt <= end_datetime
                except:
                    return False
            
            # Filter outages in time window
            window_real = [o for o in real_outages if in_time_window(o['datetime'])]
            window_false = [o for o in false_positives if in_time_window(o['datetime'])]
            
            total_in_window = len(window_real) + len(window_false)
            
            if total_in_window == 0:
                st.warning(f"âš ï¸ No outages found in the selected time window")
                return
            
            st.success(f"âœ… Found {total_in_window} reports in time window ({len(window_real)} real, {len(window_false)} false)")
            
            # Display results
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total Reports", total_in_window)
            with col2:
                st.metric("Real Outages", len(window_real))
            with col3:
                st.metric("False Positives", len(window_false))
            with col4:
                real_customers = sum(o['customers'] for o in window_real)
                st.metric("Actual Customers Affected", real_customers)
            
            # Show breakdown
            if window_real or window_false:
                col1, col2 = st.columns(2)
                
                with col1:
                    if window_real:
                        st.subheader("âœ… Real Outages in Window")
                        real_df = pd.DataFrame(window_real)
                        st.dataframe(real_df[['datetime', 'customers', 'latitude', 'longitude']])
                
                with col2:
                    if window_false:
                        st.subheader("âŒ False Positives in Window")
                        false_df = pd.DataFrame(window_false)
                        st.dataframe(false_df[['datetime', 'customers', 'latitude', 'longitude']])
            
            # Update chat context
            st.session_state.analysis_state['current_window_analysis'] = {
                'time_window': f"{start_datetime} to {end_datetime}",
                'total_reports': total_in_window,
                'real_outages': len(window_real),
                'false_positives': len(window_false),
                'real_customers_affected': sum(o['customers'] for o in window_real)
            }
            
        except Exception as e:
            logger.error(f"Time window analysis error: {str(e)}")
            st.error(f"âŒ Analysis failed: {str(e)}")

if __name__ == "__main__":
    main()